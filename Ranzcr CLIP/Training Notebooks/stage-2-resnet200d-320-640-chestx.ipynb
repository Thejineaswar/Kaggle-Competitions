{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:18.191594Z",
     "iopub.status.busy": "2021-03-03T17:10:18.190872Z",
     "iopub.status.idle": "2021-03-03T17:10:18.193427Z",
     "shell.execute_reply": "2021-03-03T17:10:18.193856Z"
    },
    "papermill": {
     "duration": 0.019776,
     "end_time": "2021-03-03T17:10:18.194121",
     "exception": false,
     "start_time": "2021-03-03T17:10:18.174345",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "# sys.path.append('./Ranger-Deep-Learning-Optimizer/ranger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:18.223982Z",
     "iopub.status.busy": "2021-03-03T17:10:18.223456Z",
     "iopub.status.idle": "2021-03-03T17:10:22.397282Z",
     "shell.execute_reply": "2021-03-03T17:10:22.396148Z"
    },
    "papermill": {
     "duration": 4.19145,
     "end_time": "2021-03-03T17:10:22.397449",
     "exception": false,
     "start_time": "2021-03-03T17:10:18.205999",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from tqdm.autonotebook import tqdm\n",
    "from pprint import pprint\n",
    "import cv2, glob, time, random, os, ast, random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import timm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts, CosineAnnealingLR\n",
    "from torch.optim import Adam, AdamW, SGD\n",
    "\n",
    "import albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# from adamp import AdamP\n",
    "# from ranger import Ranger  # this is from ranger.py\n",
    "# from ranger913A import RangerVA  # this is from ranger913A.py\n",
    "# from rangerqh import RangerQH  # this is from rangerqh.py\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:22.429881Z",
     "iopub.status.busy": "2021-03-03T17:10:22.428437Z",
     "iopub.status.idle": "2021-03-03T17:10:22.451499Z",
     "shell.execute_reply": "2021-03-03T17:10:22.451898Z"
    },
    "papermill": {
     "duration": 0.041522,
     "end_time": "2021-03-03T17:10:22.452056",
     "exception": false,
     "start_time": "2021-03-03T17:10:22.410534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adv_inception_v3',\n",
      " 'cspdarknet53',\n",
      " 'cspdarknet53_iabn',\n",
      " 'cspresnet50',\n",
      " 'cspresnet50d',\n",
      " 'cspresnet50w',\n",
      " 'cspresnext50',\n",
      " 'cspresnext50_iabn',\n",
      " 'darknet53',\n",
      " 'densenet121',\n",
      " 'densenet121d',\n",
      " 'densenet161',\n",
      " 'densenet169',\n",
      " 'densenet201',\n",
      " 'densenet264',\n",
      " 'densenet264d_iabn',\n",
      " 'densenetblur121d',\n",
      " 'dla34',\n",
      " 'dla46_c',\n",
      " 'dla46x_c',\n",
      " 'dla60',\n",
      " 'dla60_res2net',\n",
      " 'dla60_res2next',\n",
      " 'dla60x',\n",
      " 'dla60x_c',\n",
      " 'dla102',\n",
      " 'dla102x',\n",
      " 'dla102x2',\n",
      " 'dla169',\n",
      " 'dpn68',\n",
      " 'dpn68b',\n",
      " 'dpn92',\n",
      " 'dpn98',\n",
      " 'dpn107',\n",
      " 'dpn131',\n",
      " 'eca_vovnet39b',\n",
      " 'ecaresnet18',\n",
      " 'ecaresnet50',\n",
      " 'ecaresnet50d',\n",
      " 'ecaresnet50d_pruned',\n",
      " 'ecaresnet101d',\n",
      " 'ecaresnet101d_pruned',\n",
      " 'ecaresnetlight',\n",
      " 'ecaresnext26tn_32x4d',\n",
      " 'efficientnet_b0',\n",
      " 'efficientnet_b1',\n",
      " 'efficientnet_b1_pruned',\n",
      " 'efficientnet_b2',\n",
      " 'efficientnet_b2_pruned',\n",
      " 'efficientnet_b2a',\n",
      " 'efficientnet_b3',\n",
      " 'efficientnet_b3_pruned',\n",
      " 'efficientnet_b3a',\n",
      " 'efficientnet_b4',\n",
      " 'efficientnet_b5',\n",
      " 'efficientnet_b6',\n",
      " 'efficientnet_b7',\n",
      " 'efficientnet_b8',\n",
      " 'efficientnet_cc_b0_4e',\n",
      " 'efficientnet_cc_b0_8e',\n",
      " 'efficientnet_cc_b1_8e',\n",
      " 'efficientnet_el',\n",
      " 'efficientnet_em',\n",
      " 'efficientnet_es',\n",
      " 'efficientnet_l2',\n",
      " 'efficientnet_lite0',\n",
      " 'efficientnet_lite1',\n",
      " 'efficientnet_lite2',\n",
      " 'efficientnet_lite3',\n",
      " 'efficientnet_lite4',\n",
      " 'ens_adv_inception_resnet_v2',\n",
      " 'ese_vovnet19b_dw',\n",
      " 'ese_vovnet19b_slim',\n",
      " 'ese_vovnet19b_slim_dw',\n",
      " 'ese_vovnet39b',\n",
      " 'ese_vovnet39b_evos',\n",
      " 'ese_vovnet57b',\n",
      " 'ese_vovnet99b',\n",
      " 'ese_vovnet99b_iabn',\n",
      " 'fbnetc_100',\n",
      " 'gluon_inception_v3',\n",
      " 'gluon_resnet18_v1b',\n",
      " 'gluon_resnet34_v1b',\n",
      " 'gluon_resnet50_v1b',\n",
      " 'gluon_resnet50_v1c',\n",
      " 'gluon_resnet50_v1d',\n",
      " 'gluon_resnet50_v1s',\n",
      " 'gluon_resnet101_v1b',\n",
      " 'gluon_resnet101_v1c',\n",
      " 'gluon_resnet101_v1d',\n",
      " 'gluon_resnet101_v1s',\n",
      " 'gluon_resnet152_v1b',\n",
      " 'gluon_resnet152_v1c',\n",
      " 'gluon_resnet152_v1d',\n",
      " 'gluon_resnet152_v1s',\n",
      " 'gluon_resnext50_32x4d',\n",
      " 'gluon_resnext101_32x4d',\n",
      " 'gluon_resnext101_64x4d',\n",
      " 'gluon_senet154',\n",
      " 'gluon_seresnext50_32x4d',\n",
      " 'gluon_seresnext101_32x4d',\n",
      " 'gluon_seresnext101_64x4d',\n",
      " 'gluon_xception65',\n",
      " 'hrnet_w18',\n",
      " 'hrnet_w18_small',\n",
      " 'hrnet_w18_small_v2',\n",
      " 'hrnet_w30',\n",
      " 'hrnet_w32',\n",
      " 'hrnet_w40',\n",
      " 'hrnet_w44',\n",
      " 'hrnet_w48',\n",
      " 'hrnet_w64',\n",
      " 'ig_resnext101_32x8d',\n",
      " 'ig_resnext101_32x16d',\n",
      " 'ig_resnext101_32x32d',\n",
      " 'ig_resnext101_32x48d',\n",
      " 'inception_resnet_v2',\n",
      " 'inception_v3',\n",
      " 'inception_v4',\n",
      " 'legacy_senet154',\n",
      " 'legacy_seresnet18',\n",
      " 'legacy_seresnet34',\n",
      " 'legacy_seresnet50',\n",
      " 'legacy_seresnet101',\n",
      " 'legacy_seresnet152',\n",
      " 'legacy_seresnext26_32x4d',\n",
      " 'legacy_seresnext50_32x4d',\n",
      " 'legacy_seresnext101_32x4d',\n",
      " 'mixnet_l',\n",
      " 'mixnet_m',\n",
      " 'mixnet_s',\n",
      " 'mixnet_xl',\n",
      " 'mixnet_xxl',\n",
      " 'mnasnet_050',\n",
      " 'mnasnet_075',\n",
      " 'mnasnet_100',\n",
      " 'mnasnet_140',\n",
      " 'mnasnet_a1',\n",
      " 'mnasnet_b1',\n",
      " 'mnasnet_small',\n",
      " 'mobilenetv2_100',\n",
      " 'mobilenetv2_110d',\n",
      " 'mobilenetv2_120d',\n",
      " 'mobilenetv2_140',\n",
      " 'mobilenetv3_large_075',\n",
      " 'mobilenetv3_large_100',\n",
      " 'mobilenetv3_rw',\n",
      " 'mobilenetv3_small_075',\n",
      " 'mobilenetv3_small_100',\n",
      " 'nasnetalarge',\n",
      " 'pnasnet5large',\n",
      " 'regnetx_002',\n",
      " 'regnetx_004',\n",
      " 'regnetx_006',\n",
      " 'regnetx_008',\n",
      " 'regnetx_016',\n",
      " 'regnetx_032',\n",
      " 'regnetx_040',\n",
      " 'regnetx_064',\n",
      " 'regnetx_080',\n",
      " 'regnetx_120',\n",
      " 'regnetx_160',\n",
      " 'regnetx_320',\n",
      " 'regnety_002',\n",
      " 'regnety_004',\n",
      " 'regnety_006',\n",
      " 'regnety_008',\n",
      " 'regnety_016',\n",
      " 'regnety_032',\n",
      " 'regnety_040',\n",
      " 'regnety_064',\n",
      " 'regnety_080',\n",
      " 'regnety_120',\n",
      " 'regnety_160',\n",
      " 'regnety_320',\n",
      " 'res2net50_14w_8s',\n",
      " 'res2net50_26w_4s',\n",
      " 'res2net50_26w_6s',\n",
      " 'res2net50_26w_8s',\n",
      " 'res2net50_48w_2s',\n",
      " 'res2net101_26w_4s',\n",
      " 'res2next50',\n",
      " 'resnest14d',\n",
      " 'resnest26d',\n",
      " 'resnest50d',\n",
      " 'resnest50d_1s4x24d',\n",
      " 'resnest50d_4s2x40d',\n",
      " 'resnest101e',\n",
      " 'resnest200e',\n",
      " 'resnest269e',\n",
      " 'resnet18',\n",
      " 'resnet18d',\n",
      " 'resnet26',\n",
      " 'resnet26d',\n",
      " 'resnet34',\n",
      " 'resnet34d',\n",
      " 'resnet50',\n",
      " 'resnet50d',\n",
      " 'resnet101',\n",
      " 'resnet101d',\n",
      " 'resnet152',\n",
      " 'resnet152d',\n",
      " 'resnet200',\n",
      " 'resnet200d',\n",
      " 'resnet200d_320',\n",
      " 'resnetblur18',\n",
      " 'resnetblur50',\n",
      " 'resnext50_32x4d',\n",
      " 'resnext50d_32x4d',\n",
      " 'resnext101_32x4d',\n",
      " 'resnext101_32x8d',\n",
      " 'resnext101_64x4d',\n",
      " 'rexnet_100',\n",
      " 'rexnet_130',\n",
      " 'rexnet_150',\n",
      " 'rexnet_200',\n",
      " 'rexnetr_100',\n",
      " 'rexnetr_130',\n",
      " 'rexnetr_150',\n",
      " 'rexnetr_200',\n",
      " 'selecsls42',\n",
      " 'selecsls42b',\n",
      " 'selecsls60',\n",
      " 'selecsls60b',\n",
      " 'selecsls84',\n",
      " 'semnasnet_050',\n",
      " 'semnasnet_075',\n",
      " 'semnasnet_100',\n",
      " 'semnasnet_140',\n",
      " 'senet154',\n",
      " 'seresnet18',\n",
      " 'seresnet34',\n",
      " 'seresnet50',\n",
      " 'seresnet50tn',\n",
      " 'seresnet101',\n",
      " 'seresnet152',\n",
      " 'seresnet152d',\n",
      " 'seresnext26_32x4d',\n",
      " 'seresnext26d_32x4d',\n",
      " 'seresnext26t_32x4d',\n",
      " 'seresnext26tn_32x4d',\n",
      " 'seresnext50_32x4d',\n",
      " 'seresnext101_32x4d',\n",
      " 'seresnext101_32x8d',\n",
      " 'skresnet18',\n",
      " 'skresnet34',\n",
      " 'skresnet50',\n",
      " 'skresnet50d',\n",
      " 'skresnext50_32x4d',\n",
      " 'spnasnet_100',\n",
      " 'ssl_resnet18',\n",
      " 'ssl_resnet50',\n",
      " 'ssl_resnext50_32x4d',\n",
      " 'ssl_resnext101_32x4d',\n",
      " 'ssl_resnext101_32x8d',\n",
      " 'ssl_resnext101_32x16d',\n",
      " 'swsl_resnet18',\n",
      " 'swsl_resnet50',\n",
      " 'swsl_resnext50_32x4d',\n",
      " 'swsl_resnext101_32x4d',\n",
      " 'swsl_resnext101_32x8d',\n",
      " 'swsl_resnext101_32x16d',\n",
      " 'tf_efficientnet_b0',\n",
      " 'tf_efficientnet_b0_ap',\n",
      " 'tf_efficientnet_b0_ns',\n",
      " 'tf_efficientnet_b1',\n",
      " 'tf_efficientnet_b1_ap',\n",
      " 'tf_efficientnet_b1_ns',\n",
      " 'tf_efficientnet_b2',\n",
      " 'tf_efficientnet_b2_ap',\n",
      " 'tf_efficientnet_b2_ns',\n",
      " 'tf_efficientnet_b3',\n",
      " 'tf_efficientnet_b3_ap',\n",
      " 'tf_efficientnet_b3_ns',\n",
      " 'tf_efficientnet_b4',\n",
      " 'tf_efficientnet_b4_ap',\n",
      " 'tf_efficientnet_b4_ns',\n",
      " 'tf_efficientnet_b5',\n",
      " 'tf_efficientnet_b5_ap',\n",
      " 'tf_efficientnet_b5_ns',\n",
      " 'tf_efficientnet_b6',\n",
      " 'tf_efficientnet_b6_ap',\n",
      " 'tf_efficientnet_b6_ns',\n",
      " 'tf_efficientnet_b7',\n",
      " 'tf_efficientnet_b7_ap',\n",
      " 'tf_efficientnet_b7_ns',\n",
      " 'tf_efficientnet_b8',\n",
      " 'tf_efficientnet_b8_ap',\n",
      " 'tf_efficientnet_cc_b0_4e',\n",
      " 'tf_efficientnet_cc_b0_8e',\n",
      " 'tf_efficientnet_cc_b1_8e',\n",
      " 'tf_efficientnet_el',\n",
      " 'tf_efficientnet_em',\n",
      " 'tf_efficientnet_es',\n",
      " 'tf_efficientnet_l2_ns',\n",
      " 'tf_efficientnet_l2_ns_475',\n",
      " 'tf_efficientnet_lite0',\n",
      " 'tf_efficientnet_lite1',\n",
      " 'tf_efficientnet_lite2',\n",
      " 'tf_efficientnet_lite3',\n",
      " 'tf_efficientnet_lite4',\n",
      " 'tf_inception_v3',\n",
      " 'tf_mixnet_l',\n",
      " 'tf_mixnet_m',\n",
      " 'tf_mixnet_s',\n",
      " 'tf_mobilenetv3_large_075',\n",
      " 'tf_mobilenetv3_large_100',\n",
      " 'tf_mobilenetv3_large_minimal_100',\n",
      " 'tf_mobilenetv3_small_075',\n",
      " 'tf_mobilenetv3_small_100',\n",
      " 'tf_mobilenetv3_small_minimal_100',\n",
      " 'tresnet_l',\n",
      " 'tresnet_l_448',\n",
      " 'tresnet_m',\n",
      " 'tresnet_m_448',\n",
      " 'tresnet_xl',\n",
      " 'tresnet_xl_448',\n",
      " 'tv_densenet121',\n",
      " 'tv_resnet34',\n",
      " 'tv_resnet50',\n",
      " 'tv_resnet101',\n",
      " 'tv_resnet152',\n",
      " 'tv_resnext50_32x4d',\n",
      " 'vit_base_patch16_224',\n",
      " 'vit_base_patch16_384',\n",
      " 'vit_base_patch32_384',\n",
      " 'vit_base_resnet26d_224',\n",
      " 'vit_base_resnet50d_224',\n",
      " 'vit_huge_patch16_224',\n",
      " 'vit_huge_patch32_384',\n",
      " 'vit_large_patch16_224',\n",
      " 'vit_large_patch16_384',\n",
      " 'vit_large_patch32_384',\n",
      " 'vit_small_patch16_224',\n",
      " 'vit_small_resnet26d_224',\n",
      " 'vit_small_resnet50d_s3_224',\n",
      " 'vovnet39a',\n",
      " 'vovnet57a',\n",
      " 'wide_resnet50_2',\n",
      " 'wide_resnet101_2',\n",
      " 'xception',\n",
      " 'xception41',\n",
      " 'xception65',\n",
      " 'xception71']\n"
     ]
    }
   ],
   "source": [
    "# get the list of pretrained models\n",
    "model_names = timm.list_models()\n",
    "pprint(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020412,
     "end_time": "2021-03-03T17:10:22.491097",
     "exception": false,
     "start_time": "2021-03-03T17:10:22.470685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id = \"cont\"></a>\n",
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:22.880803Z",
     "iopub.status.busy": "2021-03-03T17:10:22.879898Z",
     "iopub.status.idle": "2021-03-03T17:10:22.882312Z",
     "shell.execute_reply": "2021-03-03T17:10:22.882952Z"
    },
    "papermill": {
     "duration": 0.379156,
     "end_time": "2021-03-03T17:10:22.883123",
     "exception": false,
     "start_time": "2021-03-03T17:10:22.503967",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8 # 8 for bigger architectures\n",
    "VAL_BATCH_SIZE = 32\n",
    "EPOCHS = 17 # train upto 10 epochs\n",
    "IMG_SIZE = 640 # 384 for bigger architectures\n",
    "if BATCH_SIZE == 8:\n",
    "    ITER_FREQ = 400\n",
    "else:\n",
    "    ITER_FREQ = 200\n",
    "NUM_WORKERS = 8\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "SEED = 1111\n",
    "N_FOLDS = 5\n",
    "TR_FOLDS = [0,1,2,3,4]\n",
    "START_FOLD = 0\n",
    "\n",
    "target_cols=['ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal',\n",
    "                 'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "                 'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal',\n",
    "                 'Swan Ganz Catheter Present']\n",
    "\n",
    "MODEL_PATH = '../input/stage-2-resnet200d-320-640-chestx/Stage2_resnet200d_320_fold_0_epoch_14.pth'\n",
    "MODEL_ARCH = 'resnet200d_320' # tf_efficientnet_b4_ns, tf_efficientnet_b5_ns, resnext50_32x4d, seresnet152d\n",
    "TEACHER_MODEL_PATH = '../input/stage-1-resnet200d-320-640-chestx/stage1_resnet200d_320_fold_0_epoch_4.pth'\n",
    "WEIGHTS = [0.5, 1]\n",
    "\n",
    "LR = 5e-4\n",
    "MIN_LR = 1e-6 # SAM, CosineAnnealingWarmRestarts\n",
    "WEIGHT_DECAY = 1e-6\n",
    "MOMENTUM = 0.9\n",
    "T_0 = EPOCHS # SAM, CosineAnnealingWarmRestarts\n",
    "MAX_NORM = 1000\n",
    "T_MAX = 5\n",
    "ITERS_TO_ACCUMULATE = 1\n",
    "\n",
    "BASE_OPTIMIZER = SGD #for SAM, Ranger\n",
    "OPTIMIZER = 'Adam' # Ranger, AdamW, AdamP, SGD, SAM\n",
    "\n",
    "SCHEDULER = 'CosineAnnealingWarmRestarts' # ReduceLROnPlateau, CosineAnnealingLR, CosineAnnealingWarmRestarts, OneCycleLR\n",
    "SCHEDULER_UPDATE = 'epoch' # batch\n",
    "\n",
    "CRITERION = 'BCE' # CrossEntropyLoss, TaylorSmoothedLoss, LabelSmoothedLoss\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:22.915516Z",
     "iopub.status.busy": "2021-03-03T17:10:22.914968Z",
     "iopub.status.idle": "2021-03-03T17:10:22.920507Z",
     "shell.execute_reply": "2021-03-03T17:10:22.919929Z"
    },
    "papermill": {
     "duration": 0.025207,
     "end_time": "2021-03-03T17:10:22.920630",
     "exception": false,
     "start_time": "2021-03-03T17:10:22.895423",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.sum = 0\n",
    "        self.avg = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val*n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def seed_torch(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_torch(SEED)\n",
    "\n",
    "def macro_multilabel_auc(label, pred):\n",
    "    aucs = []\n",
    "    for i in range(len(target_cols)):\n",
    "        aucs.append(roc_auc_score(label[:, i], pred[:, i]))\n",
    "    print(np.round(aucs, 4))\n",
    "    return np.mean(aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:22.951543Z",
     "iopub.status.busy": "2021-03-03T17:10:22.950965Z",
     "iopub.status.idle": "2021-03-03T17:10:23.266076Z",
     "shell.execute_reply": "2021-03-03T17:10:23.264942Z"
    },
    "papermill": {
     "duration": 0.333345,
     "end_time": "2021-03-03T17:10:23.266221",
     "exception": false,
     "start_time": "2021-03-03T17:10:22.932876",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../input/ranzcr-clip-catheter-line-classification/train/'\n",
    "train_df = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\n",
    "folds = pd.read_csv('../input/ranzcr-folds/train_folds.csv')\n",
    "train_annotations = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.307746Z",
     "iopub.status.busy": "2021-03-03T17:10:23.307000Z",
     "iopub.status.idle": "2021-03-03T17:10:23.310145Z",
     "shell.execute_reply": "2021-03-03T17:10:23.310646Z"
    },
    "papermill": {
     "duration": 0.030571,
     "end_time": "2021-03-03T17:10:23.310811",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.280240",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLOR_MAP = {'ETT - Abnormal': (255, 0, 0),\n",
    "             'ETT - Borderline': (0, 255, 0),\n",
    "             'ETT - Normal': (0, 0, 255),\n",
    "             'NGT - Abnormal': (255, 255, 0),\n",
    "             'NGT - Borderline': (255, 0, 255),\n",
    "             'NGT - Incompletely Imaged': (0, 255, 255),\n",
    "             'NGT - Normal': (128, 0, 0),\n",
    "             'CVC - Abnormal': (0, 128, 0),\n",
    "             'CVC - Borderline': (0, 0, 128),\n",
    "             'CVC - Normal': (128, 128, 0),\n",
    "             'Swan Ganz Catheter Present': (128, 0, 128),\n",
    "            }\n",
    "\n",
    "\n",
    "class RanzcrDataset(Dataset):\n",
    "    def __init__(self, df, df_annotations, use_annot=False, annot_size=50, transform=None):\n",
    "        self.df = df\n",
    "        self.df_annotations = df_annotations\n",
    "        self.use_annot = use_annot\n",
    "        self.annot_size = annot_size\n",
    "        self.image_id = df['StudyInstanceUID'].values\n",
    "        self.labels = df[target_cols].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_id[idx]\n",
    "        file_path = f'{TRAIN_DIR}{image_id}.jpg'\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        labels = torch.tensor(self.labels[idx]).float()\n",
    "        if self.use_annot:\n",
    "            image_annot = image.copy()\n",
    "            query_string = f\"StudyInstanceUID == '{image_id}'\"\n",
    "            df = self.df_annotations.query(query_string)\n",
    "            for i, row in df.iterrows():\n",
    "                label = row[\"label\"]\n",
    "                data = np.array(ast.literal_eval(row[\"data\"]))\n",
    "                for d in data:\n",
    "                    image_annot[d[1]-self.annot_size//2:d[1]+self.annot_size//2,\n",
    "                                d[0]-self.annot_size//2:d[0]+self.annot_size//2,\n",
    "                                :] = COLOR_MAP[label]\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image, image_annot=image_annot)\n",
    "                image = augmented['image']\n",
    "                image_annot = augmented['image_annot']\n",
    "            return image, image_annot, labels\n",
    "        else:\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image = augmented['image']\n",
    "            return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.347434Z",
     "iopub.status.busy": "2021-03-03T17:10:23.346686Z",
     "iopub.status.idle": "2021-03-03T17:10:23.349786Z",
     "shell.execute_reply": "2021-03-03T17:10:23.350167Z"
    },
    "papermill": {
     "duration": 0.02641,
     "end_time": "2021-03-03T17:10:23.350296",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.323886",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transform(*, train=True):\n",
    "    \n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.85, 1.0)),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.2, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2)),\n",
    "            A.HueSaturationValue(p=0.2, hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2),\n",
    "            A.ShiftScaleRotate(p=0.2, shift_limit=0.0625, scale_limit=0.2, rotate_limit=20),\n",
    "            A.CoarseDropout(p=0.2),\n",
    "            A.Cutout(p=0.2, max_h_size=16, max_w_size=16, fill_value=(0., 0., 0.), num_holes=16),\n",
    "            A.Normalize(mean=MEAN, std=STD),\n",
    "            ToTensorV2(),\n",
    "        ], additional_targets={'image_annot': 'image'})\n",
    "    else:\n",
    "        return A.Compose([\n",
    "#             A.CenterCrop(IMG_SIZE, IMG_SIZE),\n",
    "            A.Resize(IMG_SIZE, IMG_SIZE),\n",
    "            A.Normalize(mean=MEAN, std=STD, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013075,
     "end_time": "2021-03-03T17:10:23.375674",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.362599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.423652Z",
     "iopub.status.busy": "2021-03-03T17:10:23.420313Z",
     "iopub.status.idle": "2021-03-03T17:10:23.426226Z",
     "shell.execute_reply": "2021-03-03T17:10:23.425776Z"
    },
    "papermill": {
     "duration": 0.037328,
     "end_time": "2021-03-03T17:10:23.426331",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.389003",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet200D(nn.Module):\n",
    "    def __init__(self, model_arch, out_dim, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=False)\n",
    "        if pretrained:\n",
    "            pretrained_path = '../input/resnet200d-pretrained-weight/resnet200d_ra2-bdba9bf9.pth'\n",
    "            self.model.load_state_dict(torch.load(pretrained_path))\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "\n",
    "class SeResnet152D(nn.Module): \n",
    "    def __init__(self, model_arch, n_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "            \n",
    "class CustomEffNet(nn.Module):\n",
    "    def __init__(self, model_arch, n_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features,n_classes)\n",
    "        \n",
    "    def forward(self,x): \n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs,-1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return features, pooled_features, output \n",
    "    \n",
    "class CustomResNext(nn.Module):\n",
    "    def __init__(self, model_arch, n_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return output\n",
    "\n",
    "class CustomResNet200D(nn.Module):\n",
    "    def __init__(self, model_arch, n_classes, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=False)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, n_classes)\n",
    "        if pretrained:\n",
    "            pretrained_path = '../input/startingpointschestx/resnet200d_320_chestx.pth'\n",
    "            checkpoint = torch.load(pretrained_path)['model']\n",
    "            for key in list(checkpoint.keys()):\n",
    "                if 'model.' in key:\n",
    "                    checkpoint[key.replace('model.', '')] = checkpoint[key]\n",
    "                    del checkpoint[key]\n",
    "            self.model.load_state_dict(checkpoint) \n",
    "            print(f'load {model_arch} pretrained model')\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.global_pool = nn.Identity()\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return features, pooled_features, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.462400Z",
     "iopub.status.busy": "2021-03-03T17:10:23.460693Z",
     "iopub.status.idle": "2021-03-03T17:10:23.462984Z",
     "shell.execute_reply": "2021-03-03T17:10:23.463388Z"
    },
    "papermill": {
     "duration": 0.022926,
     "end_time": "2021-03-03T17:10:23.463510",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.440584",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, weights=[1, 1]):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.weights = weights\n",
    "        \n",
    "    def forward(self, teacher_features, features, y_pred, labels):\n",
    "        consistency_loss = nn.MSELoss()(teacher_features.view(-1), features.view(-1))\n",
    "        cls_loss = nn.BCEWithLogitsLoss()(y_pred, labels)\n",
    "        loss = self.weights[0] * consistency_loss + self.weights[1] * cls_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012474,
     "end_time": "2021-03-03T17:10:23.490638",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.478164",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[Back to CFG(Click here)](#cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.527982Z",
     "iopub.status.busy": "2021-03-03T17:10:23.527475Z",
     "iopub.status.idle": "2021-03-03T17:10:23.530891Z",
     "shell.execute_reply": "2021-03-03T17:10:23.531271Z"
    },
    "papermill": {
     "duration": 0.028129,
     "end_time": "2021-03-03T17:10:23.531399",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.503270",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GetCriterion(criterion_name, criterion=None):\n",
    "\n",
    "    if criterion_name == 'CrossEntropyLoss':\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    elif criterion_name == 'LabelSmoothingLoss':\n",
    "        criterion = LabelSmoothingLoss()\n",
    "#     elif criterion_name == 'FocalLoss':\n",
    "#         criterion = FocalLoss()\n",
    "#     elif criterion_name == 'FocalCosineLoss':\n",
    "#         criterion = FocalCosineLoss()\n",
    "    elif criterion_name == 'TaylorCrossEntropyLoss':\n",
    "        criterion = TaylorCrossEntropyLoss()\n",
    "    elif criterion_name == 'TaylorSmoothedLoss':\n",
    "        criterion = TaylorSmoothedLoss()\n",
    "    elif criterion_name == 'CutMix':\n",
    "        criterion = CutMixCriterion(criterion)\n",
    "    elif criterion_name == 'SnapMix':\n",
    "        criterion = SnapMixLoss()\n",
    "    elif criterion_name == 'CustomLoss':\n",
    "        criterion = CustomLoss(WEIGHTS)\n",
    "    elif criterion_name == 'BCE':\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    return criterion\n",
    "    \n",
    "    \n",
    "def GetScheduler(scheduler_name, optimizer, batches=None):\n",
    "    #['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'OneCycleLR', 'GradualWarmupSchedulerV2']\n",
    "    if scheduler_name == 'OneCycleLR':\n",
    "        return torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr = 1e-2,epochs = CFG.EPOCHS,\n",
    "                                                   steps_per_epoch = batches+1,pct_start = 0.1)\n",
    "    if scheduler_name == 'CosineAnnealingWarmRestarts':\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = T_0, T_mult=1,\n",
    "                                                                    eta_min=MIN_LR, last_epoch=-1)\n",
    "    elif scheduler_name == 'CosineAnnealingLR':\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=T_MAX, eta_min=0, last_epoch=-1)\n",
    "    elif scheduler_name == 'ReduceLROnPlateau':\n",
    "        return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=1, threshold=0.0001,\n",
    "                                                          cooldown=0, min_lr=MIN_LR)\n",
    "#     elif scheduler_name == 'GradualWarmupSchedulerV2':\n",
    "#         return GradualWarmupSchedulerV2(optimizer=optimizer)\n",
    "    \n",
    "def GetOptimizer(optimizer_name,parameters):\n",
    "    #['Adam','Ranger']\n",
    "    if optimizer_name == 'Adam':\n",
    "#         if CFG.scheduler_name == 'GradualWarmupSchedulerV2':\n",
    "#             return torch.optim.Adam(parameters, lr=CFG.LR_START, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "#         else:\n",
    "        return torch.optim.Adam(parameters, lr=LR, weight_decay=WEIGHT_DECAY, amsgrad=False)\n",
    "    elif optimizer_name == 'AdamW':\n",
    "#         if CFG.scheduler_name == 'GradualWarmupSchedulerV2':\n",
    "#             return torch.optim.AdamW(parameters, lr=CFG.LR_START, weight_decay=CFG.weight_decay, amsgrad=False)\n",
    "#         else:\n",
    "        return torch.optim.Adam(parameters, lr=LR, weight_decay=WEIGHT_DECAY, amsgrad=False)\n",
    "    elif optimizer_name == 'AdamP':\n",
    "#         if CFG.scheduler_name == 'GradualWarmupSchedulerV2':\n",
    "#             return AdamP(parameters, lr=CFG.LR_START, weight_decay=CFG.weight_decay)\n",
    "#         else:\n",
    "        return AdamP(parameters, lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    elif optimizer_name == 'Ranger':\n",
    "        return Ranger(parameters, lr = LR, alpha = 0.5, k = 6, N_sma_threshhold = 5, \n",
    "                      betas = (0.95,0.999), weight_decay=WEIGHT_DECAY)\n",
    "    elif optimizer_name == 'SAM':\n",
    "        return SAM(parameters, BASE_OPTIMIZER, lr=0.1, momentum=0.9,weight_decay=0.0005)\n",
    "    \n",
    "    elif optimizer_name == 'AdamP':\n",
    "        return AdamP(parameters, lr=LR, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012606,
     "end_time": "2021-03-03T17:10:23.556671",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.544065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.592963Z",
     "iopub.status.busy": "2021-03-03T17:10:23.592436Z",
     "iopub.status.idle": "2021-03-03T17:10:23.596376Z",
     "shell.execute_reply": "2021-03-03T17:10:23.595941Z"
    },
    "papermill": {
     "duration": 0.027014,
     "end_time": "2021-03-03T17:10:23.596479",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.569465",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(model, dataloader, teacher_model, device, epoch, optimizer, criterion):\n",
    "    \n",
    "    data_time = AverageMeter()\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    \n",
    "    model.train()\n",
    "    # https://pytorch.org/docs/stable/notes/amp_examples.html#gradient-accumulation\n",
    "    scaler = GradScaler()\n",
    "    start_time = time.time()\n",
    "    loader = tqdm(dataloader, total=len(dataloader))\n",
    "    for step, (images, images_annot, labels) in enumerate(loader):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_features, _, _ = teacher_model(images_annot.to(device))\n",
    "\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        data_time.update(time.time() - start_time)\n",
    "\n",
    "        with autocast():\n",
    "            features, _, output = model(images)\n",
    "            loss = criterion(teacher_features, features, output, labels)\n",
    "#             output = model(images)\n",
    "#             loss = criterion(output, labels)\n",
    "            losses.update(loss.item(), BATCH_SIZE)\n",
    "        \n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm = MAX_NORM)\n",
    "\n",
    "            if (step+1) % ITERS_TO_ACCUMULATE == 0:\n",
    "                scaler.step(optimizer)\n",
    "                # Update the scale for next iteration.\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "        \n",
    "#         if scheduler is not None and SCHEDULER_UPDATE == 'batch':\n",
    "#             scheduler.step()\n",
    "\n",
    "        batch_time.update(time.time() - start_time)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if step % ITER_FREQ == 0:\n",
    "            \n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s),\\t'\n",
    "                  'Data Time {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t'\n",
    "                  'Loss: {loss.val:.4f} ({loss.avg:.4f})'.format((epoch+1),\n",
    "                                                                  step, len(dataloader),\n",
    "                                                                  batch_time=batch_time,\n",
    "                                                                  data_time=data_time,\n",
    "                                                                  loss=losses))\n",
    "                                                                             #accuracy=accuracies))\n",
    "        # To check the loss real-time while iterating over data.   'Accuracy {accuracy.val:.4f} ({accuracy.avg:.4f})'\n",
    "        loader.set_description(f'Training Epoch {epoch+1}/{EPOCHS}')\n",
    "        loader.set_postfix(loss=losses.avg) #accuracy=accuracies.avg)\n",
    "#         del images, labels\n",
    "        \n",
    "    return losses.avg#, accuracies.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.629665Z",
     "iopub.status.busy": "2021-03-03T17:10:23.629030Z",
     "iopub.status.idle": "2021-03-03T17:10:23.631841Z",
     "shell.execute_reply": "2021-03-03T17:10:23.631458Z"
    },
    "papermill": {
     "duration": 0.022647,
     "end_time": "2021-03-03T17:10:23.631954",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.609307",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_fn(epoch, model, criterion, val_loader, device):\n",
    "    \n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    accuracies = AverageMeter()\n",
    "    PREDS = []\n",
    "    TARGETS = []\n",
    "    loader = tqdm(val_loader, total=len(val_loader))\n",
    "    with torch.no_grad():  # without torch.no_grad() will make the CUDA run OOM.\n",
    "        for step, (images, labels) in enumerate(loader):\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "#             output = model(images)\n",
    "            _, _, output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            losses.update(loss.item(), BATCH_SIZE)\n",
    "            PREDS += [output.sigmoid()]\n",
    "            TARGETS += [labels.detach().cpu()]\n",
    "#             accuracy = (F.softmax(output).argmax(dim=1) == labels).float().mean()\n",
    "#             accuracies.update(accuracy.item(), VAL_BATCH_SIZE)\n",
    "            loader.set_description(f'Validating Epoch {epoch+1}/{EPOCHS}')\n",
    "            loader.set_postfix(loss=losses.avg)#, accuracy=accuracies.avg)\n",
    "#             del images, labels\n",
    "    PREDS = torch.cat(PREDS).cpu().numpy()\n",
    "    TARGETS = torch.cat(TARGETS).cpu().numpy()\n",
    "    roc_auc = macro_multilabel_auc(TARGETS, PREDS)\n",
    "#     if scheduler is not None:\n",
    "#         scheduler.step()\n",
    "        \n",
    "    return losses.avg, roc_auc# accuracies.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012771,
     "end_time": "2021-03-03T17:10:23.657765",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.644994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "[Back to CFG(Click here)](#cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012762,
     "end_time": "2021-03-03T17:10:23.683486",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.670724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.725516Z",
     "iopub.status.busy": "2021-03-03T17:10:23.724807Z",
     "iopub.status.idle": "2021-03-03T17:10:23.727409Z",
     "shell.execute_reply": "2021-03-03T17:10:23.727813Z"
    },
    "papermill": {
     "duration": 0.03149,
     "end_time": "2021-03-03T17:10:23.727953",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.696463",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engine(device, folds, fold, model_path=None):\n",
    "    \n",
    "    trn_idx = folds[folds['kfold'] != fold].index\n",
    "    val_idx = folds[folds['kfold'] == fold].index\n",
    "\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    train_folds = train_folds[train_folds['StudyInstanceUID'].isin(train_annotations['StudyInstanceUID'].unique())].reset_index(drop=True)\n",
    "\n",
    "    train_data = RanzcrDataset(train_folds, train_annotations, use_annot=True, transform=get_transform())\n",
    "    val_data = RanzcrDataset(valid_folds, train_annotations, use_annot=False, transform=get_transform(train=False))            \n",
    "    \n",
    "    train_loader = DataLoader(train_data,\n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              shuffle=True, \n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              pin_memory=True, # enables faster data transfer to CUDA-enabled GPUs.\n",
    "                              drop_last=True)\n",
    "    val_loader = DataLoader(val_data, \n",
    "                            batch_size=VAL_BATCH_SIZE,\n",
    "                            num_workers=NUM_WORKERS,\n",
    "                            shuffle=False, \n",
    "                            pin_memory=True,\n",
    "                            drop_last=False)\n",
    "    \n",
    "    teacher_model = CustomResNet200D(MODEL_ARCH, 11, pretrained=False)\n",
    "    teacher_model.load_state_dict(torch.load(TEACHER_MODEL_PATH))\n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    teacher_model.eval()\n",
    "    teacher_model.to(device)\n",
    "    model = CustomResNet200D(MODEL_ARCH, 11, pretrained=True)\n",
    "    if model_path is not None:\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        START_EPOCH = int((model_path.split('_')[-1]).split('.')[0])\n",
    "    else:\n",
    "        model = CustomResNet200D(MODEL_ARCH, 11, pretrained=True)\n",
    "        START_EPOCH = 0\n",
    "    model.to(device)\n",
    "    \n",
    "    params = filter(lambda p: p.requires_grad, model.parameters())    \n",
    "    optimizer = GetOptimizer(OPTIMIZER, params)\n",
    "    \n",
    "    train_criterion = CustomLoss(weights=WEIGHTS).to(device)        \n",
    "    val_criterion = GetCriterion(CRITERION).to(device)\n",
    "    \n",
    "    scheduler = GetScheduler(SCHEDULER, optimizer)\n",
    "    \n",
    "    loss = []\n",
    "    accuracy = []\n",
    "    for epoch in range(START_EPOCH, EPOCHS):\n",
    "        \n",
    "        epoch_start = time.time()        \n",
    "        avg_loss = train_fn(model, train_loader, teacher_model, device, epoch, optimizer, train_criterion)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        avg_val_loss, roc_auc_score = valid_fn(epoch, model, val_criterion, val_loader, device)\n",
    "        epoch_end = time.time() - epoch_start\n",
    "#         if scheduler is not None and SCHEDULER_UPDATE == 'epoch':\n",
    "#             scheduler.step()\n",
    "        if isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "        print(f'Validation ROC AUC Score after epoch {epoch+1}: {roc_auc_score:.4f}')\n",
    "        loss.append(avg_loss)\n",
    "#         accuracy.append(avg_accuracy)\n",
    "        \n",
    "        content = f'Fold {fold} Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f} roc_auc_score: {roc_auc_score:.4f} time: {epoch_end:.0f}s'\n",
    "        with open(f'Stage2_{MODEL_ARCH}_{IMG_SIZE}.txt', 'a') as appender:\n",
    "            appender.write(content + '\\n')                                         # avg_train_accuracy: {avg_accuracy:.4f}\n",
    "        \n",
    "\n",
    "        torch.save(model.state_dict(), f'Stage2_{MODEL_ARCH}_fold_{fold}_epoch_{(epoch+1)}.pth')\n",
    "#         torch.save(model, f'GPU_{MODEL_ARCH}_fold_{fold}_epoch_{(epoch+1)}')\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return loss#{'loss':loss, 'accuracy':accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-03T17:10:23.762996Z",
     "iopub.status.busy": "2021-03-03T17:10:23.762366Z",
     "iopub.status.idle": "2021-03-03T17:10:38.094247Z",
     "shell.execute_reply": "2021-03-03T17:10:38.094758Z"
    },
    "papermill": {
     "duration": 14.353725,
     "end_time": "2021-03-03T17:10:38.094924",
     "exception": false,
     "start_time": "2021-03-03T17:10:23.741199",
     "status": "completed"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Fold 0 Starting =====\n",
      "load resnet200d_320 pretrained model\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/stage-2-resnet200d-320-640-chestx/Stage2_resnet200d_320_fold_0_epoch_14.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-062483f5c81c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'===== Fold {fold} Starting ====='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfold_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time taken in fold {fold}: {time.time()-fold_start}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ee1a78836ddb>\u001b[0m in \u001b[0;36mengine\u001b[0;34m(device, folds, fold, model_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomResNet200D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_ARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mSTART_EPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/stage-2-resnet200d-320-640-chestx/Stage2_resnet200d_320_fold_0_epoch_14.pth'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    if MODEL_PATH is not None:\n",
    "        START_FOLD = int(MODEL_PATH.split('_')[-3])  ## ChestX 89.64,  ## resnet200d_320 package 85...\n",
    "    \n",
    "    for fold in range(START_FOLD, N_FOLDS):\n",
    "        if fold == 1:\n",
    "            break\n",
    "        print(f'===== Fold {fold} Starting =====')\n",
    "        fold_start = time.time()\n",
    "        logs = engine(DEVICE, folds, fold, MODEL_PATH)\n",
    "        print(f'Time taken in fold {fold}: {time.time()-fold_start}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.63019,
   "end_time": "2021-03-03T17:10:40.224722",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-03T17:10:13.594532",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
