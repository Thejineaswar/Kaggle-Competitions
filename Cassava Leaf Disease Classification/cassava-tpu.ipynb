{"cells":[{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/docs/tpu"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"raw","source":"package_path = '../input/pytorch-image-models/pytorch-image-models-master'\n#'../input/efficientnet-pytorch-07/efficientnet_pytorch-0.7.0'\nimport os, sys\nsys.path.append(package_path)\n\n# Install Torch-XLA (PyTorch with Accelerated Linear Algebra (XLA) support)\nos.system('curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py')\nos.system('python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev')\n# For parallelization in TPUs\nos.system('export XLA_USE_BF16=1')\nos.system('export XLA_TENSOR_ALLOCATOR_MAXSIZE=100000000')"},{"metadata":{"trusted":true},"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version 1.7\n!pip install timm\n\nimport os\n# For parallelization in TPUs\nos.environ[\"XLA_USE_BF16\"] = \"1\"\nos.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom pprint import pprint\nfrom tqdm.notebook import tqdm\nimport os, cv2, glob, time, random, gc\nfrom datetime import datetime\n\nfrom sklearn.metrics import accuracy_score\nfrom logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n\nimport timm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader, distributed\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\n# https://pytorch.org/xla/release/1.7/index.html\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.distributed.xla_multiprocessing as xmp\nimport torch_xla.utils.serialization as xser\n\nimport ignite.distributed as igd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":"xm.get_xla_supported_devices()"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"TRAIN_DIR = '../input/cassava-leaf-disease-classification/train_images/'\nLABEL_JSON_PATH = '../input/cassava-leaf-disease-classification/label_num_to_disease_map.json'\nTEST_DIR = '../input/cassava-leaf-disease-classification/test_images'\n\ndf = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv')\ndf_test = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"label_map = pd.read_json('../input/cassava-leaf-disease-classification/label_num_to_disease_map.json', orient='index')\ndisplay(label_map)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# get the list of pretrained models\nmodel_names = timm.list_models(pretrained=True)\npprint(model_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"IMG_SIZE = 384\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\nBATCH_SIZE = 8\nITER_FREQ = 100\nEPOCHS = 2\nNUM_WORKERS = 4\nMODEL_ARCH = 'tf_efficientnet_b4_ns'\nLR = 1e-5\nWEIGHT_DECAY = 1e-6\nITERS_TO_ACCUMULATE = 1\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n# https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/multi-core-alexnet-fashion-mnist.ipynb\n# Do not initialize device type here.\n# device = xm.xla_device()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=1111)\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class AverageMeter(object):\n    \n    # Keeps track of most recent, average, sum, and count of a metric.\n    \n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class CLD_train_ds(Dataset):\n    \n    def __init__(self, df, transform=None):\n        self.df = df\n        self.image_id = df['image_id'].values\n        self.label = df['label'].values\n        self.transform = transform\n        \n    def __len__(self) -> int:\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        \n        image_id = self.image_id[idx]\n        img = cv2.imread(TRAIN_DIR + image_id)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n        img = img / 255.0\n        \n        if self.transform:\n            trans_img = self.transform(image=img)\n            img = trans_img['image']\n            \n        label = torch.tensor(self.label[idx]).long()\n        \n        return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def get_transform(*, train=True):\n    \n    if train:\n        return A.Compose([\n            A.RandomResizedCrop(IMG_SIZE, IMG_SIZE),\n            A.Transpose(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.Normalize(mean=MEAN, std=STD),\n            ToTensorV2(),\n        ])\n    else:\n        return A.Compose([\n            A.CenterCrop(IMG_SIZE, IMG_SIZE),\n            A.Resize(IMG_SIZE, IMG_SIZE),\n            A.Normalize(mean=MEAN, std=STD),\n            ToTensorV2(),\n        ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"class eff_net(nn.Module):\n    \n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained, n_class)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n# class resnext(nn.Module):\n#     def __init__(self, model_name, n_class, pretrained=False):\n#         super().__init__()\n#         self.model = timm.create_model(model_name, pretrained=pretrained)\n#         n_features = self.model.fc.in_features\n#         self.model.fc = nn.Linear(n_features, n_class)\n\n#     def forward(self, x):\n#         x = self.model(x)\n#         return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def train_fn(model, dataloader, epoch, optimizer, device, criterion):\n    \n    model.train()\n    \n    losses = AverageMeter()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    accuracies = AverageMeter()\n    \n    start = time.time()\n#     epoch_loss = 0\n#     epoch_accuracy = 0\n    global_step = 0\n    \n    loader = tqdm(dataloader, total=len(dataloader))\n    for step, (images, labels) in enumerate(loader):\n        \n        images = images.to(device, dtype=torch.float32)\n        labels = labels.to(device, dtype=torch.int64)\n        \n        data_time.update(time.time() - start)\n        \n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        \n        output = model(images)\n        loss = criterion(output, labels)\n        loss = loss / ITERS_TO_ACCUMULATE\n        losses.update(loss.item(), BATCH_SIZE)\n        \n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n    \n        # Calculate Accuracy\n        accuracy = (output.argmax(dim=1) == labels).float().mean()\n        accuracies.update(accuracy.item(), BATCH_SIZE)\n        \n        if (step+1) % ITERS_TO_ACCUMULATE == 0:\n            \n            # Run the provided optimizer step and issue the XLA device step computation.\n            xm.optimizer_step(optimizer)    \n            global_step += 1\n            \n        batch_time.update(time.time() - start)\n        start = time.time()\n\n#         epoch_loss += loss\n#         epoch_accuracy += accuracy\n        \n        if step % ITER_FREQ == 0:\n            \n            xm.master_print('Epoch: [{0}][{1}/{2}]\\t'\n                            'Batch Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s), '\n                            'Data Time {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t'\n                            'Loss: {loss.val:.4f} ({loss.avg:.4f}), '\n                            'Accuracy {accuracy.val:.4f} ({accuracy.avg:.4f})'.format((epoch+1),\n                                                                                      step, len(dataloader),\n                                                                                      batch_time=batch_time,\n                                                                                      data_time=data_time,\n                                                                                      loss=losses,\n                                                                                      accuracy=accuracies))\n        # To check the loss real-time while iterating over data.\n        loader.set_postfix(loss=losses.avg, accuracy=accuracies.avg)\n        \n#         del images, labels\n        \n    return losses.avg, accuracies.avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def engine():\n    \n    train_data = CLD_train_ds(df, transform = get_transform())\n    \n    # https://pytorch.org/docs/stable/data.html#torch.utils.data.distributed.DistributedSampler\n    train_sampler = distributed.DistributedSampler(train_data,\n                                                   # .xrt_world_size() retrieves the number of devices(cores)\n                                                   # which is taking part of the replication.\n                                                   num_replicas=xm.xrt_world_size(),\n                                                   # .get_ordinal() retrieves the replication ordinal of the \n                                                   # current process. The ordinals range from 0 to xrt_world_size()-1\n                                                   rank=xm.get_ordinal(),\n                                                   shuffle=True)\n    \n    train_loader = DataLoader(train_data,\n                              batch_size=BATCH_SIZE,\n                              sampler=train_sampler,\n                              num_workers=NUM_WORKERS,\n                              drop_last=True,\n                              pin_memory=True # enables faster data transfer to CUDA-enabled GPUs.\n                             )\n    \n    # Acquires the (unique) Cloud TPU core corresponding to this process's index\n    device = xm.xla_device()\n    model = eff_net(MODEL_ARCH, 5, True)\n    xm.set_rng_state(1111, device)\n    model.to(device)\n    \n    params = filter(lambda p: p.requires_grad, model.parameters())\n    lr = LR * xm.xrt_world_size()  # Number of cores taking part in replication.\n    optimizer = torch.optim.Adam(params, lr=lr, weight_decay=WEIGHT_DECAY)\n    criterion = nn.CrossEntropyLoss().to(device)\n    \n    loss = []\n    accuracy = []\n    \n    xm.master_print(f\"Initializing training on {xm.xrt_world_size()} TPU cores.\")\n    start_time = datetime.now()\n    xm.master_print(f\"Start Time: {start_time}\")\n    \n    for epoch in range(EPOCHS):\n        \n        gc.collect()\n        # ParallelLoader wraps an existing PyTorch DataLoader with background data upload.\n        pl_loader = pl.ParallelLoader(train_loader, [device])\n        # we pass a parelleloader and not a dataloader (for parellel training only).\n        \n        epoch_start = time.time()\n        avg_loss, avg_accuracy = train_fn(model,\n                                          # .per_device_loader() gets the loader\n                                          # iterator object for the given device.\n                                          pl_loader.per_device_loader(device),\n                                          epoch, optimizer, device, criterion)\n        epoch_end = time.time() - epoch_start\n        loss.append(avg_loss)\n        accuracy.append(avg_accuracy)\n\n        content = f'Epoch {epoch+1} - avg_loss: {avg_loss:.4f} avg_accuracy: {avg_accuracy:.4f} time: {epoch_end:.0f}s'\n        with open(f'TPU_log_{MODEL_ARCH}.txt', 'a') as appender:\n            appender.write(content + '\\n')\n\n        # LOGGER.info(f'Epoch {epoch+1} - avg_loss: {avg_loss:.4f} avg_accuracy: {avg_accuracy:.4f} time: {epoch_end:.0f}s')\n        # Save the model to use it for inference.\n        xm.save(model.state_dict(), f'TPU_{MODEL_ARCH}_epoch_{(epoch+1)}.pth')\n        xm.save(model, f'TPU_{MODEL_ARCH}_epoch_{(epoch+1)}')\n        \n#         xser.save(model.state_dict(), f'TPU_XSER_{MODEL_ARCH}_epoch_{(epoch+1)}', master_only=False)\n        \n        gc.collect()\n        del pl_loader\n        torch.cuda.empty_cache()\n    \n    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n    \n    return {'loss':loss, 'accuracy':accuracy}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"# def main():\n#     logs = engine()\n\ndef _mp_fn(rank, flags):\n    # Sets the default torch.Tensor type to given floating point type tensor. \n    torch.set_default_tensor_type(\"torch.FloatTensor\")\n    logs = engine()\n    \nFLAGS = {}\nxmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logs","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}