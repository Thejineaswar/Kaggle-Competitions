{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer.git\n!pip install adamp","execution_count":1,"outputs":[{"output_type":"stream","text":"Cloning into 'Ranger-Deep-Learning-Optimizer'...\nremote: Enumerating objects: 66, done.\u001b[K\nremote: Counting objects: 100% (66/66), done.\u001b[K\nremote: Compressing objects: 100% (60/60), done.\u001b[K\nremote: Total 135 (delta 34), reused 17 (delta 6), pack-reused 69\u001b[K\nReceiving objects: 100% (135/135), 181.12 KiB | 1.02 MiB/s, done.\nResolving deltas: 100% (59/59), done.\nCollecting adamp\n  Downloading adamp-0.3.0.tar.gz (5.1 kB)\nBuilding wheels for collected packages: adamp\n  Building wheel for adamp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5998 sha256=73b6d6525fda88d547418858dbd57e32939a22e9741f311a99e6072d82e1cc45\n  Stored in directory: /root/.cache/pip/wheels/bb/95/21/ced2d2cb9944e3a72e58fece7958973eed3fd8d0aeb6e2e450\nSuccessfully built adamp\nInstalling collected packages: adamp\nSuccessfully installed adamp-0.3.0\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\nsys.path.append('./Ranger-Deep-Learning-Optimizer/ranger')\n# sys.setrecursionlimit(10**6)","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom datetime import datetime\nfrom tqdm.autonotebook import tqdm\nfrom pprint import pprint\nimport cv2, glob, time, random, os, warnings\nwarnings.filterwarnings('ignore')\n\nimport timm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\nfrom torch.optim import Adam, AdamW, SGD\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom adamp import AdamP\n# https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n# from ranger import Ranger  # this is from ranger.py\nfrom ranger913A import RangerVA  # this is from ranger913A.py\nfrom rangerqh import RangerQH  # this is from rangerqh.py\nfrom ranger2020 import Ranger","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  \"\"\"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the list of pretrained models\nmodel_names = timm.list_models()\npprint(model_names)","execution_count":4,"outputs":[{"output_type":"stream","text":"['adv_inception_v3',\n 'cspdarknet53',\n 'cspdarknet53_iabn',\n 'cspresnet50',\n 'cspresnet50d',\n 'cspresnet50w',\n 'cspresnext50',\n 'cspresnext50_iabn',\n 'darknet53',\n 'densenet121',\n 'densenet121d',\n 'densenet161',\n 'densenet169',\n 'densenet201',\n 'densenet264',\n 'densenet264d_iabn',\n 'densenetblur121d',\n 'dla34',\n 'dla46_c',\n 'dla46x_c',\n 'dla60',\n 'dla60_res2net',\n 'dla60_res2next',\n 'dla60x',\n 'dla60x_c',\n 'dla102',\n 'dla102x',\n 'dla102x2',\n 'dla169',\n 'dpn68',\n 'dpn68b',\n 'dpn92',\n 'dpn98',\n 'dpn107',\n 'dpn131',\n 'eca_vovnet39b',\n 'ecaresnet18',\n 'ecaresnet50',\n 'ecaresnet50d',\n 'ecaresnet50d_pruned',\n 'ecaresnet101d',\n 'ecaresnet101d_pruned',\n 'ecaresnetlight',\n 'ecaresnext26tn_32x4d',\n 'efficientnet_b0',\n 'efficientnet_b1',\n 'efficientnet_b1_pruned',\n 'efficientnet_b2',\n 'efficientnet_b2_pruned',\n 'efficientnet_b2a',\n 'efficientnet_b3',\n 'efficientnet_b3_pruned',\n 'efficientnet_b3a',\n 'efficientnet_b4',\n 'efficientnet_b5',\n 'efficientnet_b6',\n 'efficientnet_b7',\n 'efficientnet_b8',\n 'efficientnet_cc_b0_4e',\n 'efficientnet_cc_b0_8e',\n 'efficientnet_cc_b1_8e',\n 'efficientnet_el',\n 'efficientnet_em',\n 'efficientnet_es',\n 'efficientnet_l2',\n 'efficientnet_lite0',\n 'efficientnet_lite1',\n 'efficientnet_lite2',\n 'efficientnet_lite3',\n 'efficientnet_lite4',\n 'ens_adv_inception_resnet_v2',\n 'ese_vovnet19b_dw',\n 'ese_vovnet19b_slim',\n 'ese_vovnet19b_slim_dw',\n 'ese_vovnet39b',\n 'ese_vovnet39b_evos',\n 'ese_vovnet57b',\n 'ese_vovnet99b',\n 'ese_vovnet99b_iabn',\n 'fbnetc_100',\n 'gluon_inception_v3',\n 'gluon_resnet18_v1b',\n 'gluon_resnet34_v1b',\n 'gluon_resnet50_v1b',\n 'gluon_resnet50_v1c',\n 'gluon_resnet50_v1d',\n 'gluon_resnet50_v1s',\n 'gluon_resnet101_v1b',\n 'gluon_resnet101_v1c',\n 'gluon_resnet101_v1d',\n 'gluon_resnet101_v1s',\n 'gluon_resnet152_v1b',\n 'gluon_resnet152_v1c',\n 'gluon_resnet152_v1d',\n 'gluon_resnet152_v1s',\n 'gluon_resnext50_32x4d',\n 'gluon_resnext101_32x4d',\n 'gluon_resnext101_64x4d',\n 'gluon_senet154',\n 'gluon_seresnext50_32x4d',\n 'gluon_seresnext101_32x4d',\n 'gluon_seresnext101_64x4d',\n 'gluon_xception65',\n 'hrnet_w18',\n 'hrnet_w18_small',\n 'hrnet_w18_small_v2',\n 'hrnet_w30',\n 'hrnet_w32',\n 'hrnet_w40',\n 'hrnet_w44',\n 'hrnet_w48',\n 'hrnet_w64',\n 'ig_resnext101_32x8d',\n 'ig_resnext101_32x16d',\n 'ig_resnext101_32x32d',\n 'ig_resnext101_32x48d',\n 'inception_resnet_v2',\n 'inception_v3',\n 'inception_v4',\n 'legacy_senet154',\n 'legacy_seresnet18',\n 'legacy_seresnet34',\n 'legacy_seresnet50',\n 'legacy_seresnet101',\n 'legacy_seresnet152',\n 'legacy_seresnext26_32x4d',\n 'legacy_seresnext50_32x4d',\n 'legacy_seresnext101_32x4d',\n 'mixnet_l',\n 'mixnet_m',\n 'mixnet_s',\n 'mixnet_xl',\n 'mixnet_xxl',\n 'mnasnet_050',\n 'mnasnet_075',\n 'mnasnet_100',\n 'mnasnet_140',\n 'mnasnet_a1',\n 'mnasnet_b1',\n 'mnasnet_small',\n 'mobilenetv2_100',\n 'mobilenetv2_110d',\n 'mobilenetv2_120d',\n 'mobilenetv2_140',\n 'mobilenetv3_large_075',\n 'mobilenetv3_large_100',\n 'mobilenetv3_rw',\n 'mobilenetv3_small_075',\n 'mobilenetv3_small_100',\n 'nasnetalarge',\n 'pnasnet5large',\n 'regnetx_002',\n 'regnetx_004',\n 'regnetx_006',\n 'regnetx_008',\n 'regnetx_016',\n 'regnetx_032',\n 'regnetx_040',\n 'regnetx_064',\n 'regnetx_080',\n 'regnetx_120',\n 'regnetx_160',\n 'regnetx_320',\n 'regnety_002',\n 'regnety_004',\n 'regnety_006',\n 'regnety_008',\n 'regnety_016',\n 'regnety_032',\n 'regnety_040',\n 'regnety_064',\n 'regnety_080',\n 'regnety_120',\n 'regnety_160',\n 'regnety_320',\n 'res2net50_14w_8s',\n 'res2net50_26w_4s',\n 'res2net50_26w_6s',\n 'res2net50_26w_8s',\n 'res2net50_48w_2s',\n 'res2net101_26w_4s',\n 'res2next50',\n 'resnest14d',\n 'resnest26d',\n 'resnest50d',\n 'resnest50d_1s4x24d',\n 'resnest50d_4s2x40d',\n 'resnest101e',\n 'resnest200e',\n 'resnest269e',\n 'resnet18',\n 'resnet18d',\n 'resnet26',\n 'resnet26d',\n 'resnet34',\n 'resnet34d',\n 'resnet50',\n 'resnet50d',\n 'resnet101',\n 'resnet101d',\n 'resnet152',\n 'resnet152d',\n 'resnet200',\n 'resnet200d',\n 'resnet200d_320',\n 'resnetblur18',\n 'resnetblur50',\n 'resnext50_32x4d',\n 'resnext50d_32x4d',\n 'resnext101_32x4d',\n 'resnext101_32x8d',\n 'resnext101_64x4d',\n 'rexnet_100',\n 'rexnet_130',\n 'rexnet_150',\n 'rexnet_200',\n 'rexnetr_100',\n 'rexnetr_130',\n 'rexnetr_150',\n 'rexnetr_200',\n 'selecsls42',\n 'selecsls42b',\n 'selecsls60',\n 'selecsls60b',\n 'selecsls84',\n 'semnasnet_050',\n 'semnasnet_075',\n 'semnasnet_100',\n 'semnasnet_140',\n 'senet154',\n 'seresnet18',\n 'seresnet34',\n 'seresnet50',\n 'seresnet50tn',\n 'seresnet101',\n 'seresnet152',\n 'seresnet152d',\n 'seresnext26_32x4d',\n 'seresnext26d_32x4d',\n 'seresnext26t_32x4d',\n 'seresnext26tn_32x4d',\n 'seresnext50_32x4d',\n 'seresnext101_32x4d',\n 'seresnext101_32x8d',\n 'skresnet18',\n 'skresnet34',\n 'skresnet50',\n 'skresnet50d',\n 'skresnext50_32x4d',\n 'spnasnet_100',\n 'ssl_resnet18',\n 'ssl_resnet50',\n 'ssl_resnext50_32x4d',\n 'ssl_resnext101_32x4d',\n 'ssl_resnext101_32x8d',\n 'ssl_resnext101_32x16d',\n 'swsl_resnet18',\n 'swsl_resnet50',\n 'swsl_resnext50_32x4d',\n 'swsl_resnext101_32x4d',\n 'swsl_resnext101_32x8d',\n 'swsl_resnext101_32x16d',\n 'tf_efficientnet_b0',\n 'tf_efficientnet_b0_ap',\n 'tf_efficientnet_b0_ns',\n 'tf_efficientnet_b1',\n 'tf_efficientnet_b1_ap',\n 'tf_efficientnet_b1_ns',\n 'tf_efficientnet_b2',\n 'tf_efficientnet_b2_ap',\n 'tf_efficientnet_b2_ns',\n 'tf_efficientnet_b3',\n 'tf_efficientnet_b3_ap',\n 'tf_efficientnet_b3_ns',\n 'tf_efficientnet_b4',\n 'tf_efficientnet_b4_ap',\n 'tf_efficientnet_b4_ns',\n 'tf_efficientnet_b5',\n 'tf_efficientnet_b5_ap',\n 'tf_efficientnet_b5_ns',\n 'tf_efficientnet_b6',\n 'tf_efficientnet_b6_ap',\n 'tf_efficientnet_b6_ns',\n 'tf_efficientnet_b7',\n 'tf_efficientnet_b7_ap',\n 'tf_efficientnet_b7_ns',\n 'tf_efficientnet_b8',\n 'tf_efficientnet_b8_ap',\n 'tf_efficientnet_cc_b0_4e',\n 'tf_efficientnet_cc_b0_8e',\n 'tf_efficientnet_cc_b1_8e',\n 'tf_efficientnet_el',\n 'tf_efficientnet_em',\n 'tf_efficientnet_es',\n 'tf_efficientnet_l2_ns',\n 'tf_efficientnet_l2_ns_475',\n 'tf_efficientnet_lite0',\n 'tf_efficientnet_lite1',\n 'tf_efficientnet_lite2',\n 'tf_efficientnet_lite3',\n 'tf_efficientnet_lite4',\n 'tf_inception_v3',\n 'tf_mixnet_l',\n 'tf_mixnet_m',\n 'tf_mixnet_s',\n 'tf_mobilenetv3_large_075',\n 'tf_mobilenetv3_large_100',\n 'tf_mobilenetv3_large_minimal_100',\n 'tf_mobilenetv3_small_075',\n 'tf_mobilenetv3_small_100',\n 'tf_mobilenetv3_small_minimal_100',\n 'tresnet_l',\n 'tresnet_l_448',\n 'tresnet_m',\n 'tresnet_m_448',\n 'tresnet_xl',\n 'tresnet_xl_448',\n 'tv_densenet121',\n 'tv_resnet34',\n 'tv_resnet50',\n 'tv_resnet101',\n 'tv_resnet152',\n 'tv_resnext50_32x4d',\n 'vit_base_patch16_224',\n 'vit_base_patch16_384',\n 'vit_base_patch32_384',\n 'vit_base_resnet26d_224',\n 'vit_base_resnet50d_224',\n 'vit_huge_patch16_224',\n 'vit_huge_patch32_384',\n 'vit_large_patch16_224',\n 'vit_large_patch16_384',\n 'vit_large_patch32_384',\n 'vit_small_patch16_224',\n 'vit_small_resnet26d_224',\n 'vit_small_resnet50d_s3_224',\n 'vovnet39a',\n 'vovnet57a',\n 'wide_resnet50_2',\n 'wide_resnet101_2',\n 'xception',\n 'xception41',\n 'xception65',\n 'xception71']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## CFG"},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16\nEPOCHS = 3\nIMG_SIZE = 512\nITER_FREQ = 500\nNUM_WORKERS = 8\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\nSEED = 1111\n\nLR = 1e-4\nMIN_LR = 5e-5 # SAM, CosineAnnealingWarmRestarts\nWEIGHT_DECAY = 1e-6\nMOMENTUM = 0.9\nT_0 = EPOCHS # SAM, CosineAnnealingWarmRestarts\nMAX_NORM = 1000\n\nSNAPMIX = True\nSNAPMIX_ALPHA = 5.0\nSNAPMIX_PCT = 0.5\n\nMODEL_ARCH = 'tf_efficientnet_b3_ns'\nITERS_TO_ACCUMULATE = 1\n\nCUTMIX = False\nCM_START = 0\nCM_ALPHA = 1\n\nBASE_OPTIMIZER = SGD #for SAM, Ranger\nOPTIMIZER = 'AdamW'\nif OPTIMIZER == 'SAM':\n    SAM = True\n\nSCHEDULER = 'CosineAnnealingWarmRestarts'\nSCHEDULER_UPDATE = 'epoch'\n\nCRITERION = 'CrossEntropyLoss'\nLABEL_SMOOTH = 0.15\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AverageMeter(object):\n    \n    def __init__(self):\n        self.reset()\n        \n    def reset(self):\n        self.val = 0\n        self.sum = 0\n        self.avg = 0\n        self.count = 0\n        \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val*n\n        self.count += n\n        self.avg = self.sum / self.count\n\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(SEED)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../input/cassava-leaf-disease-merged/train/'\ndf = pd.read_csv('../input/cassava-leaf-disease-merged/merged.csv')\n# df","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CLD_train_DS(Dataset):\n    \n    def __init__(self, df, transform=None):\n        self.df = df\n        self.image_id = df['image_id'].values\n        self.label = df['label'].values\n        self.transform = transform\n        \n    def __len__(self) -> int:\n        return len(self.df)\n        \n    def __getitem__(self, idx):\n        \n        image_id = self.image_id[idx]\n        img = cv2.imread(TRAIN_DIR + image_id)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n        img = img / 255.0\n        \n        if self.transform:\n            trans_img = self.transform(image=img)\n            img = trans_img['image']\n            \n        label = torch.tensor(self.label[idx]).long()\n        \n        return img, label","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_transform(*, train=True):\n    \n    if train:\n        return A.Compose([\n            A.RandomResizedCrop(IMG_SIZE, IMG_SIZE),\n            A.Transpose(p=0.5),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.Normalize(mean=MEAN, std=STD),\n            ToTensorV2(),\n        ])\n    else:\n        return A.Compose([\n            A.CenterCrop(IMG_SIZE, IMG_SIZE),\n            A.Resize(IMG_SIZE, IMG_SIZE),\n            A.Normalize(mean=MEAN, std=STD),\n            ToTensorV2(),\n        ])","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SAM optimizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SAM(torch.optim.Optimizer):\n    def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\n        assert rho >= 0.0, f\"Invalid rho, should be non-negative: {rho}\"\n\n        defaults = dict(rho=rho, **kwargs)\n        super(SAM, self).__init__(params, defaults)\n\n        self.base_optimizer = base_optimizer(self.param_groups, **kwargs)\n        self.param_groups = self.base_optimizer.param_groups\n\n    @torch.no_grad()\n    def first_step(self, zero_grad=False):\n        grad_norm = self._grad_norm()\n        for group in self.param_groups:\n            scale = group[\"rho\"] / (grad_norm + 1e-12)\n\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                e_w = p.grad * scale.to(p)\n                p.add_(e_w)  # climb to the local maximum \"w + e(w)\"\n                self.state[p][\"e_w\"] = e_w\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def second_step(self, zero_grad=False):\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                if p.grad is None: continue\n                p.sub_(self.state[p][\"e_w\"])  # get back to \"w\" from \"w + e(w)\"\n\n        self.base_optimizer.step()  # do the actual \"sharpness-aware\" update\n\n        if zero_grad: self.zero_grad()\n\n    @torch.no_grad()\n    def step(self, closure=None):\n        assert closure is not None, \"Sharpness Aware Minimization requires closure, but it was not provided\"\n        closure = torch.enable_grad()(closure)  # the closure should do a full forward-backward pass\n\n        self.first_step(zero_grad=True)\n        closure()\n        self.second_step()\n\n    def _grad_norm(self):\n        shared_device = self.param_groups[0][\"params\"][0].device  # put everything on the same device, in case of model parallelism\n        norm = torch.norm(\n                    torch.stack([\n                        p.grad.norm(p=2).to(shared_device)\n                        for group in self.param_groups for p in group[\"params\"]\n                        if p.grad is not None\n                    ]),\n                    p=2\n               )\n        return norm","execution_count":24,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loss Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"class LabelSmoothingLoss(nn.Module): \n    def __init__(self, classes=5, smoothing=0.0, dim=-1): \n        super(LabelSmoothingLoss, self).__init__() \n        self.confidence = 1.0 - smoothing \n        self.smoothing = smoothing \n        self.cls = classes \n        self.dim = dim \n    def forward(self, pred, target): \n        if CRITERION == 'LabelSmoothingLoss':\n            pred = pred.log_softmax(dim=self.dim) \n        with torch.no_grad():\n            true_dist = torch.zeros_like(pred) \n            true_dist.fill_(self.smoothing / (self.cls - 1)) \n            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n    \nclass TaylorSoftmax(nn.Module):\n    '''\n    This is the autograd version\n    '''\n    def __init__(self, dim=1, n=2):\n        super(TaylorSoftmax, self).__init__()\n        assert n % 2 == 0\n        self.dim = dim\n        self.n = n\n\n    def forward(self, x):\n        '''\n        usage similar to nn.Softmax:\n            >>> mod = TaylorSoftmax(dim=1, n=4)\n            >>> inten = torch.randn(1, 32, 64, 64)\n            >>> out = mod(inten)\n        '''\n        fn = torch.ones_like(x)\n        denor = 1.\n        for i in range(1, self.n+1):\n            denor *= i\n            fn = fn + x.pow(i) / denor\n        out = fn / fn.sum(dim=self.dim, keepdims=True)\n        return out\n    \nclass TaylorCrossEntropyLoss(nn.Module):\n    '''\n    This is the autograd version\n    '''\n    def __init__(self, n=2, ignore_index=-1, reduction='mean'):\n        super(TaylorCrossEntropyLoss, self).__init__()\n        assert n % 2 == 0\n        self.taylor_softmax = TaylorSoftmax(dim=1, n=n)\n        self.reduction = reduction\n        self.ignore_index = ignore_index\n\n    def forward(self, logits, labels):\n        '''\n        usage similar to nn.CrossEntropyLoss:\n            >>> crit = TaylorCrossEntropyLoss(n=4)\n            >>> inten = torch.randn(1, 10, 64, 64)\n            >>> label = torch.randint(0, 10, (1, 64, 64))\n            >>> out = crit(inten, label)\n        '''\n        log_probs = self.taylor_softmax(logits).log()\n        loss = F.nll_loss(log_probs, labels, reduction=self.reduction,\n                ignore_index=self.ignore_index)\n        return loss\n    \nclass TaylorSmoothedLoss(nn.Module):\n\n    def __init__(self, n=2, ignore_index=-1, reduction='mean', smoothing=0.2):\n        super(TaylorSmoothedLoss, self).__init__()\n        assert n % 2 == 0\n        self.taylor_softmax = TaylorSoftmax(dim=1, n=n)\n        self.reduction = reduction\n        self.ignore_index = ignore_index\n        self.lab_smooth = LabelSmoothingLoss(5, smoothing=LABEL_SMOOTH)\n\n    def forward(self, logits, labels):\n\n        log_probs = self.taylor_softmax(logits).log()\n        #loss = F.nll_loss(log_probs, labels, reduction=self.reduction,\n        #        ignore_index=self.ignore_index)\n        loss = self.lab_smooth(log_probs, labels)\n        return loss\n    \nclass CutMixCriterion(nn.Module):\n    def __init__(self, criterion):\n        super(CutMixCriterion, self).__init__()\n        self.criterion = criterion\n\n    def forward(self, preds, labels):\n        targets1 = labels[:,0] \n        targets2 = labels[:,1]\n        lam = labels[0,2]\n        return lam * self.criterion(\n            preds, targets1) + (1 - lam) * self.criterion(preds, targets2)","execution_count":25,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Augmentations"},{"metadata":{},"cell_type":"markdown","source":"SnapMix"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rand_bbox(size, lam):\n    W = size[2]\n    H = size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w = np.int(W * cut_rat)\n    cut_h = np.int(H * cut_rat)\n\n    # uniform\n    cx = np.random.randint(W)\n    cy = np.random.randint(H)\n\n    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n    bby1 = np.clip(cy - cut_h // 2, 0, H)\n    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n    bby2 = np.clip(cy + cut_h // 2, 0, H)\n\n    return bbx1, bby1, bbx2, bby2\n\ndef get_spm(input,target,model):\n    imgsize = (IMG_SIZE, IMG_SIZE)\n    bs = input.size(0)\n    with torch.no_grad():\n        output,fms = model(input)\n        clsw = model.classifier\n        weight = clsw.weight.data\n        bias = clsw.bias.data\n        weight = weight.view(weight.size(0),weight.size(1),1,1)\n        fms = F.relu(fms)\n        poolfea = F.adaptive_avg_pool2d(fms,(1,1)).squeeze()\n        clslogit = F.softmax(clsw.forward(poolfea))\n        logitlist = []\n        for i in range(bs):\n            logitlist.append(clslogit[i,target[i]])\n        clslogit = torch.stack(logitlist)\n\n        out = F.conv2d(fms, weight, bias=bias)\n\n        outmaps = []\n        for i in range(bs):\n            evimap = out[i,target[i]]\n            outmaps.append(evimap)\n\n        outmaps = torch.stack(outmaps)\n        if imgsize is not None:\n            outmaps = outmaps.view(outmaps.size(0),1,outmaps.size(1),outmaps.size(2))\n            outmaps = F.interpolate(outmaps,imgsize,mode='bilinear',align_corners=False)\n\n        outmaps = outmaps.squeeze()\n\n        for i in range(bs):\n            outmaps[i] -= outmaps[i].min()\n            outmaps[i] /= outmaps[i].sum()\n\n\n    return outmaps,clslogit\n\n\ndef snapmix(input, target, alpha, model=None):\n\n    r = np.random.rand(1)\n    lam_a = torch.ones(input.size(0))\n    lam_b = 1 - lam_a\n    target_b = target.clone()\n\n    if True:\n        wfmaps,_ = get_spm(input, target, model)\n        bs = input.size(0)\n        lam = np.random.beta(alpha, alpha)\n        lam1 = np.random.beta(alpha, alpha)\n        rand_index = torch.randperm(bs).cuda()\n        wfmaps_b = wfmaps[rand_index,:,:]\n        target_b = target[rand_index]\n\n        same_label = target == target_b\n        bbx1, bby1, bbx2, bby2 = rand_bbox(input.size(), lam)\n        bbx1_1, bby1_1, bbx2_1, bby2_1 = rand_bbox(input.size(), lam1)\n\n        area = (bby2-bby1)*(bbx2-bbx1)\n        area1 = (bby2_1-bby1_1)*(bbx2_1-bbx1_1)\n\n        if  area1 > 0 and  area>0:\n            ncont = input[rand_index, :, bbx1_1:bbx2_1, bby1_1:bby2_1].clone()\n            ncont = F.interpolate(ncont, size=(bbx2-bbx1,bby2-bby1), mode='bilinear', align_corners=True)\n            input[:, :, bbx1:bbx2, bby1:bby2] = ncont\n            lam_a = 1 - wfmaps[:,bbx1:bbx2,bby1:bby2].sum(2).sum(1)/(wfmaps.sum(2).sum(1)+1e-8)\n            lam_b = wfmaps_b[:,bbx1_1:bbx2_1,bby1_1:bby2_1].sum(2).sum(1)/(wfmaps_b.sum(2).sum(1)+1e-8)\n            tmp = lam_a.clone()\n            lam_a[same_label] += lam_b[same_label]\n            lam_b[same_label] += tmp[same_label]\n            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input.size()[-1] * input.size()[-2]))\n            lam_a[torch.isnan(lam_a)] = lam\n            lam_b[torch.isnan(lam_b)] = 1-lam\n\n    return input,target,target_b,lam_a.cuda(),lam_b.cuda()\n\nclass SnapMixLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n    def forward(self, criterion, outputs, ya, yb, lam_a, lam_b):\n        loss_a = criterion(outputs, ya)\n        loss_b = criterion(outputs, yb)\n        loss = torch.mean(loss_a * lam_a + loss_b * lam_b)\n        return loss","execution_count":26,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CutMix"},{"metadata":{"trusted":true},"cell_type":"code","source":"def cutmix(batch, alpha):\n    data, targets = batch\n\n    indices = torch.randperm(data.size(0))\n    shuffled_data = data[indices]\n    shuffled_targets = targets[indices]\n\n    lam = np.random.beta(alpha, alpha)\n\n    image_h, image_w = data.shape[2:]\n    cx = np.random.uniform(0, image_w)\n    cy = np.random.uniform(0, image_h)\n    w = image_w * np.sqrt(1 - lam)\n    h = image_h * np.sqrt(1 - lam)\n    x0 = int(np.round(max(cx - w / 2, 0)))\n    x1 = int(np.round(min(cx + w / 2, image_w)))\n    y0 = int(np.round(max(cy - h / 2, 0)))\n    y1 = int(np.round(min(cy + h / 2, image_h)))\n\n    data[:, :, y0:y1, x0:x1] = shuffled_data[:, :, y0:y1, x0:x1]\n    return_targets = torch.zeros((len(targets),3),dtype=torch.int64)\n    return_targets[:,0] = targets\n    return_targets[:,1] = shuffled_targets\n    return_targets[0,2] = lam\n\n    return data, return_targets\n        \nclass CutMixCollator:\n    def __init__(self, alpha):\n        self.alpha = alpha\n\n    def __call__(self, batch):\n        batch = torch.utils.data.dataloader.default_collate(batch)\n        batch = cutmix(batch, self.alpha)\n        return batch","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Modified for SnapMix\nclass CassavaNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        backbone = timm.create_model(MODEL_ARCH, pretrained=True)\n        n_features = backbone.classifier.in_features\n        self.backbone = nn.Sequential(*backbone.children())[:-2]\n        self.classifier = nn.Linear(n_features, 5)\n        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n\n    def forward_features(self, x):\n        x = self.backbone(x)\n        return x\n\n    def forward(self, x):\n        feats = self.forward_features(x)\n        x = self.pool(feats).view(x.size(0), -1)\n        x = self.classifier(x)\n        return x, feats\n\nclass CustomEffNet(nn.Module):   \n    def __init__(self, model_arch, n_class, pretrained=True):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained, n_class)\n        n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Linear(n_features, n_class)\n        \n    def forward(self, x):\n        x = self.model(x)\n        return x\n    \nclass CustomResNext(nn.Module):\n    def __init__(self, MODEL_ARCH, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(MODEL_ARCH, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nclass CustomViT(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_arch, pretrained=pretrained)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x\n\nclass CustomDeiT(nn.Module):\n    def __init__(self, model_arch, n_class, pretrained=False):\n        super().__init__()\n        self.model = torch.hub.load('facebookresearch/deit:main', model_arch, pretrained=pretrained)\n        n_features = self.model.head.in_features\n        self.model.head = nn.Linear(n_features, n_class)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def GetCriterion(criterion_name, criterion=None):\n#     if criterion_name == 'BiTemperedLoss':\n#         criterion = BiTemperedLogistic()\n#     elif criterion_name == 'SymmetricCrossEntropyLoss':\n#         criterion = SymmetricCrossEntropy()\n    if criterion_name == 'CrossEntropyLoss':\n        criterion = nn.CrossEntropyLoss()\n    elif criterion_name == 'LabelSmoothingLoss':\n        criterion = LabelSmoothingLoss()\n#     elif criterion_name == 'FocalLoss':\n#         criterion = FocalLoss()\n#     elif criterion_name == 'FocalCosineLoss':\n#         criterion = FocalCosineLoss()\n    elif criterion_name == 'TaylorCrossEntropyLoss':\n        criterion = TaylorCrossEntropyLoss()\n    elif criterion_name == 'TaylorSmoothedLoss':\n        criterion = TaylorSmoothedLoss()\n    elif criterion_name == 'CutMix':\n        criterion = CutMixCriterion(criterion)\n    elif criterion_name == 'SnapMix':\n        criterion = SnapMixLoss()\n    return criterion\n    \n    \ndef GetScheduler(scheduler_name, optimizer, batches=None):\n    #['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'OneCycleLR', 'GradualWarmupSchedulerV2']\n    if scheduler_name == 'OneCycleLR':\n        return torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr = 1e-2,epochs = CFG.EPOCHS,\n                                                   steps_per_epoch = batches+1,pct_start = 0.1)\n    if scheduler_name == 'CosineAnnealingWarmRestarts':\n        return torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = T_0, T_mult=1,\n                                                                    eta_min=MIN_LR, last_epoch=-1)\n    elif scheduler_name == 'CosineAnnealingLR':\n        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = CFG.T_max, eta_min=0, last_epoch=-1)\n    elif scheduler_name == 'ReduceLROnPlateau':\n        return torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=1, threshold=0.0001,\n                                                          cooldown=0, min_lr=MIN_LR)\n#     elif scheduler_name == 'GradualWarmupSchedulerV2':\n#         return GradualWarmupSchedulerV2(optimizer=optimizer)\n    \ndef GetOptimizer(optimizer_name,parameters):\n    #['Adam','Ranger']\n    if optimizer_name == 'Adam':\n#         if CFG.scheduler_name == 'GradualWarmupSchedulerV2':\n#             return torch.optim.Adam(parameters, lr=CFG.LR_START, weight_decay=CFG.weight_decay, amsgrad=False)\n#         else:\n        return torch.optim.Adam(parameters, lr=LR, weight_decay=WEIGHT_DECAY, amsgrad=False)\n    elif optimizer_name == 'AdamW':\n#         if CFG.scheduler_name == 'GradualWarmupSchedulerV2':\n#             return torch.optim.AdamW(parameters, lr=CFG.LR_START, weight_decay=CFG.weight_decay, amsgrad=False)\n#         else:\n        return torch.optim.Adam(parameters, lr=LR, weight_decay=WEIGHT_DECAY, amsgrad=False)\n    elif optimizer_name == 'AdamP':\n#         if CFG.scheduler_name == 'GradualWarmupSchedulerV2':\n#             return AdamP(parameters, lr=CFG.LR_START, weight_decay=CFG.weight_decay)\n#         else:\n        return AdamP(parameters, lr=LR, weight_decay=WEIGHT_DECAY)\n    elif optimizer_name == 'Ranger':\n        return Ranger(parameters, lr = LR, alpha = 0.5, k = 6, N_sma_threshhold = 5, \n                      betas = (0.95,0.999), weight_decay=WEIGHT_DECAY)\n    elif optimizer_name == 'SAM':\n        return SAM(parameters, BASE_OPTIMIZER, lr=0.1, momentum=0.9,weight_decay=0.0005)","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(model, dataloader, device, epoch, optimizer, criterion, scheduler):\n    \n    data_time = AverageMeter()\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    accuracies = AverageMeter()\n    \n    model.train()\n    scaler = GradScaler()\n    start_time = time.time()\n    loader = tqdm(dataloader, total=len(dataloader))\n    for step, (images, labels) in enumerate(loader):\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        data_time.update(time.time() - start_time)\n        \n        with autocast():\n            \n            if SNAPMIX:\n                rand = np.random.rand()\n                if rand > (1.0-SNAPMIX_PCT):\n                    X, ya, yb, lam_a, lam_b = snapmix(images, labels, SNAPMIX_ALPHA, model)\n                    output, _ = model(X)\n                    snapmix_criterion = GetCriterion('SnapMix')\n                    loss = snapmix_criterion(criterion, output, ya, yb, lam_a, lam_b)\n                else:\n                    output, _ = model(images)\n                    criterion = GetCriterion('CrossEntropyLoss').to(device)\n                    loss = torch.mean(criterion(output, labels))\n                losses.update(loss.item(), BATCH_SIZE)\n                \n            else:\n                output = model(images)\n                loss = criterion(output, labels)\n                if CUTMIX:\n                    losses.update(loss, BATCH_SIZE)\n                else:\n                    losses.update(loss.item(), BATCH_SIZE)\n            \n        scaler.scale(loss).backward()\n        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm = MAX_NORM)\n\n        if not CUTMIX:\n                accuracy = (output.argmax(dim=1) == labels).float().mean()\n        else:\n            if labels[0,2] >= 0.5:\n                accuracy = (output.argmax(dim=1) == labels[:,0]).float().mean()\n            else:\n                accuracy = (output.argmax(dim=1) == labels[:,1]).float().mean()\n\n        accuracies.update(accuracy.item(), BATCH_SIZE)\n        \n        scaler.step(optimizer)\n        scaler.update()\n        optimizer.zero_grad()\n        \n        if scheduler is not None and SCHEDULER_UPDATE == 'batch':\n            scheduler.step()\n\n        batch_time.update(time.time() - start_time)\n        start_time = time.time()\n        \n        if step % ITER_FREQ == 0:\n            \n            print('Epoch: [{0}][{1}/{2}]\\t'\n                  'Batch Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s), '\n                  'Data Time {data_time.val:.3f}s ({data_time.avg:.3f}s)\\t'\n                  'Loss: {loss.val:.4f} ({loss.avg:.4f}), '\n                  'Accuracy {accuracy.val:.4f} ({accuracy.avg:.4f})'.format((epoch+1),\n                                                                             step, len(dataloader),\n                                                                             batch_time=batch_time,\n                                                                             data_time=data_time,\n                                                                             loss=losses,\n                                                                             accuracy=accuracies))\n        loader.set_postfix(loss=losses.avg, accuracy=accuracies.avg)\n    if scheduler is not None and SCHEDULER_UPDATE == 'epoch':\n        scheduler.step()\n        \n    return losses.avg, accuracies.avg","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Main"},{"metadata":{"trusted":true},"cell_type":"code","source":"def engine(device, model_path=None):\n    \n    train_data = CLD_train_DS(df, transform=get_transform())\n\n    if CUTMIX:\n        print('Using CutMix')\n        collator = CutMixCollator(CM_ALPHA)\n        criterion = GetCriterion('CutMix', GetCriterion(CRITERION)).to(device)                \n    \n    train_loader = DataLoader(train_data, \n                              batch_size=BATCH_SIZE, \n                              shuffle=True, \n                              num_workers=NUM_WORKERS,\n#                               collate_fn=collator,   # Uncomment when using CutMix\n                              pin_memory=True, \n                              drop_last=True)\n    \n    batches = len(train_loader)\n    if model_path is not None:\n        model = torch.load(model_path)\n        START_EPOCH = int(model_path.split('_')[-1])\n    else:\n        model = CassavaNet()\n        START_EPOCH = 0\n    model.to(device)\n    \n    params = filter(lambda p: p.requires_grad, model.parameters())    \n    optimizer = GetOptimizer(OPTIMIZER, params)\n    if not CUTMIX:\n        criterion = GetCriterion(CRITERION).to(device)\n    else:\n        criterion = GetCriterion('CutMix', GetCriterion(CRITERION)).to(device)\n    scheduler = GetScheduler(SCHEDULER, optimizer)\n    \n    loss = []\n    accuracy = []\n    for epoch in range(START_EPOCH, EPOCHS):\n        \n        epoch_start = time.time()        \n        avg_loss, avg_accuracy = train_fn(model, train_loader, device, epoch, optimizer, criterion, scheduler)\n        epoch_end = time.time() - epoch_start\n        \n        loss.append(avg_loss)\n        accuracy.append(avg_accuracy)\n        \n        content = f'Epoch {epoch+1} - avg_loss: {avg_loss:.4f} avg_accuracy: {avg_accuracy:.4f} time: {epoch_end:.0f}s'\n        with open(f'GPU_{MODEL_ARCH}_{OPTIMIZER}_{CRITERION}.txt', 'a') as appender:\n            appender.write(content + '\\n')\n        \n        # Save the model to use it for inference.\n        torch.save(model.state_dict(), f'GPU_{MODEL_ARCH}_epoch_{(epoch+1)}.pth')\n        torch.save(model, f'GPU_{MODEL_ARCH}_epoch_{(epoch+1)}')\n        torch.cuda.empty_cache()\n    \n    return {'loss':loss, 'accuracy':accuracy}","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logs = engine(DEVICE)","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1646 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f69ca25c875470e880a65ae6b082152"}},"metadata":{}},{"output_type":"stream","text":"Epoch: [1][0/1646]\tBatch Time 5.094s (5.094s), Data Time 3.655s (3.655s)\tLoss: 2.2262 (2.2262), Accuracy 0.1875 (0.1875)\nEpoch: [1][500/1646]\tBatch Time 0.579s (0.584s), Data Time 0.008s (0.018s)\tLoss: 1.3033 (1.1869), Accuracy 0.7500 (0.6831)\nEpoch: [1][1000/1646]\tBatch Time 0.676s (0.579s), Data Time 0.008s (0.014s)\tLoss: 0.8196 (1.1104), Accuracy 0.6875 (0.7120)\nEpoch: [1][1500/1646]\tBatch Time 0.608s (0.577s), Data Time 0.009s (0.013s)\tLoss: 1.0750 (1.0722), Accuracy 0.8750 (0.7260)\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1646 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f14b570e732410a9b4133f34cb6c06c"}},"metadata":{}},{"output_type":"stream","text":"Epoch: [2][0/1646]\tBatch Time 6.124s (6.124s), Data Time 3.416s (3.416s)\tLoss: 0.4640 (0.4640), Accuracy 0.8125 (0.8125)\nEpoch: [2][500/1646]\tBatch Time 0.623s (0.586s), Data Time 0.021s (0.017s)\tLoss: 1.8323 (0.9681), Accuracy 0.5000 (0.7672)\nEpoch: [2][1000/1646]\tBatch Time 0.569s (0.580s), Data Time 0.009s (0.014s)\tLoss: 1.3079 (0.9668), Accuracy 0.8750 (0.7690)\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}